# ===================================================================
#           KakaoTalk AI Chatbot - Robust Final Version
#
#   - Author: Gemini (as a world-class AI expert coder)
#   - Architecture: Total Knowledge Ingestion (Robust & Stable)
#   - Features:
#       - Absolute pathing for file access, ensuring stability in any environment.
#       - Enhanced error logging for easier debugging.
#       - Initialization logic moved for better compatibility with Gunicorn.
# ===================================================================

import os
import pandas as pd
import threading
import requests
import json
from flask import Flask, request, jsonify
from openai import OpenAI
from dotenv import load_dotenv

# --- âš™ï¸ ì‹œìŠ¤í…œ ì„¤ì • (Configuration) ---
CHAT_MODEL = "gpt-5-nano"

# --- í™˜ê²½ ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
load_dotenv()
app = Flask(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- ì „ì²´ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜ ---
KNOWLEDGE_TEXTBOOK = ""

# ===================================================================
#      Part 1: ì§€ì‹ ë² ì´ìŠ¤ ì»´íŒŒì¼ ì—”ì§„ (ìˆ˜ì •ë¨)
# ===================================================================

def load_and_format_knowledge_base():
    """
    (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ì‹¤í–‰)
    knowledge.csvë¥¼ ë¡œë“œí•˜ê³ , AIê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ Markdown í˜•ì‹ì˜
    ê±°ëŒ€í•œ í…ìŠ¤íŠ¸ 'êµê³¼ì„œ'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    global KNOWLEDGE_TEXTBOOK
    try:
        # <<< CHANGED #1: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© >>>
        # app.py íŒŒì¼ì´ ìˆëŠ” ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ knowledge.csv íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ ì–´ë–¤ í™˜ê²½ì—ì„œ ì‹¤í–‰ë˜ë”ë¼ë„ í•­ìƒ ì •í™•í•œ ìœ„ì¹˜ì˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        current_dir = os.path.dirname(__file__)
        csv_path = os.path.join(current_dir, 'knowledge.csv')
        
        print(f"Attempting to load knowledge base from: {csv_path}")

        # <<< CHANGED #2: ì¸ì½”ë”© ì§€ì • >>>
        # CSV íŒŒì¼ì˜ ì¸ì½”ë”© ë¬¸ì œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ 'utf-8-sig'ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
        kb_dataframe = pd.read_csv(csv_path, encoding='utf-8-sig')
        
        print("âœ… Knowledge base CSV file loaded successfully. Compiling into a single textbook...")

        formatted_texts = []
        for category, group in kb_dataframe.groupby('category'):
            formatted_texts.append(f"## {category}\n")
            for index, row in group.iterrows():
                formatted_texts.append(f"### {row['topic']}\n{row['content']}\n")
        
        KNOWLEDGE_TEXTBOOK = "\n".join(formatted_texts)
        
        print("âœ… Knowledge textbook successfully compiled.")

    # <<< CHANGED #3: í¬ê´„ì ì¸ ì˜¤ë¥˜ ì²˜ë¦¬ >>>
    # FileNotFoundError ë¿ë§Œ ì•„ë‹ˆë¼, Pandas íŒŒì‹± ì˜¤ë¥˜ ë“± ëª¨ë“  ì¢…ë¥˜ì˜ ì˜ˆì™¸ë¥¼ ì¡ì•„ëƒ…ë‹ˆë‹¤.
    except Exception as e:
        # ì–´ë–¤ ì¢…ë¥˜ì˜ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ ì •í™•íˆ ë¡œê·¸ì— ë‚¨ê¹ë‹ˆë‹¤.
        print(f"ğŸš¨ FATAL ERROR during knowledge base initialization: {e}")
        KNOWLEDGE_TEXTBOOK = "ì˜¤ë¥˜: ì§€ì‹ ë² ì´ìŠ¤ íŒŒì¼ì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


# ===================================================================
#      Part 2: AI ë‹µë³€ ìƒì„± ì—”ì§„ (ê¸°ì¡´ê³¼ ë™ì¼)
# ===================================================================
def generate_ai_response_total_knowledge(user_message: str) -> str:
    if not KNOWLEDGE_TEXTBOOK or "ì˜¤ë¥˜:" in KNOWLEDGE_TEXTBOOK:
        # ì‚¬ìš©ìì—ê²Œ ì „ë‹¬ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì±—ë´‡ì˜ ì§€ì‹ ë² ì´ìŠ¤ì— ë¬¸ì œê°€ ë°œìƒí•˜ì—¬ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì˜¤ë¥˜ ì›ì¸: {KNOWLEDGE_TEXTBOOK})"
    
    system_instruction = f"""
    ë‹¹ì‹ ì€ í¬ë¦¬ìŠ¤ì°¬ë©”ëª¨ë¦¬ì–¼íŒŒí¬ì˜ ëª¨ë“  ê·œì •ê³¼ ì •ë³´ë¥¼ ì™„ë²½í•˜ê²Œ ì•”ê¸°í•œ ìµœìƒê¸‰ AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    (ì´í•˜ í”„ë¡¬í”„íŠ¸ ë‚´ìš©ì€ ì´ì „ê³¼ ë™ì¼)
    ---
    [í¬ë¦¬ìŠ¤ì°¬ë©”ëª¨ë¦¬ì–¼íŒŒí¬ ê³µì‹ ì§€ì‹ ë² ì´ìŠ¤]
    {KNOWLEDGE_TEXTBOOK}
    ---
    """
    try:
        response = client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "system", "content": system_instruction}, {"role": "user", "content": user_message}],
            temperature=0.2,
            max_completion_tokens=2000,
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"ğŸš¨ OpenAI API call failed: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. AI ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."


# ===================================================================
#      Part 3 & 4: ì½œë°± ì²˜ë¦¬ ë° ë©”ì¸ ì„œë²„ ë¡œì§ (ì´ˆê¸°í™” ìœ„ì¹˜ ë³€ê²½)
# ===================================================================
# (process_and_send_callback í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼)
def process_and_send_callback(user_message, callback_url):
    print("Starting background processing (Total Knowledge Ingestion)...")
    ai_response_text = generate_ai_response_total_knowledge(user_message)
    final_response_data = {"version": "2.0", "template": {"outputs": [{"simpleText": {"text": ai_response_text}}]}}
    headers = {'Content-Type': 'application/json'}
    try:
        requests.post(callback_url, data=json.dumps(final_response_data), headers=headers, timeout=10)
        print("âœ… Successfully sent final response via callback.")
    except requests.exceptions.RequestException as e:
        print(f"ğŸš¨ Failed to send callback to Kakao: {e}")

# (callback í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼)
@app.route('/callback', methods=['POST'])
def callback():
    req = request.get_json()
    user_message = req['userRequest']['utterance']
    callback_url = req['userRequest'].get('callbackUrl')
    print(f"\n--- New Request Received ---")
    print(f"User Query: {user_message}")
    if callback_url:
        thread = threading.Thread(target=process_and_send_callback, args=(user_message, callback_url))
        thread.start()
        return jsonify({"version": "2.0", "useCallback": True})
    else:
        ai_response_text = generate_ai_response_total_knowledge(user_message)
        return jsonify({"version": "2.0", "template": {"outputs": [{"simpleText": {"text": ai_response_text}}]}})


# <<< CHANGED #4: Gunicorn í˜¸í™˜ì„±ì„ ìœ„í•œ ì´ˆê¸°í™” ìœ„ì¹˜ ë³€ê²½ >>>
# if __name__ == '__main__': ë¸”ë¡ ë°–ìœ¼ë¡œ ì´ˆê¸°í™” í•¨ìˆ˜ë¥¼ ì´ë™ì‹œí‚µë‹ˆë‹¤.
# ì´ë ‡ê²Œ í•˜ë©´ gunicornì´ ì•±ì„ ì‹¤í–‰í•  ë•Œë„ ì´ í•¨ìˆ˜ê°€ í™•ì‹¤í•˜ê²Œ í˜¸ì¶œë©ë‹ˆë‹¤.
initialize_knowledge_base()

if __name__ == '__main__':
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„œë²„ ì‹¤í–‰
    port = int(os.environ.get("PORT", 8080))
    app.run(host='0.0.0.0', port=port)
# ===================================================================
#           KakaoTalk AI Chatbot - Semantic Search Architecture
#
#   - Author: Gemini (as a world-class AI expert coder)
#   - Feature: Utilizes OpenAI's embedding model for true semantic search,
#              overcoming the limitations of keyword-based retrieval.
# ===================================================================

import os
import pandas as pd
import numpy as np
from numpy.linalg import norm
import threading
import requests
import json
from flask import Flask, request, jsonify
from openai import OpenAI
from dotenv import load_dotenv

# --- í™˜ê²½ ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
load_dotenv()
app = Flask(__name__)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- ì‹œìŠ¤í…œ ì„¤ì •ê°’ ---
MAX_CONTEXT_RESULTS = 3
# (ì‹ ê·œ) ì˜ë¯¸ ê²€ìƒ‰ì—ì„œ ìœ ì‚¬ë„ì˜ ê¸°ì¤€ì . ì´ ì ìˆ˜ ì´ìƒë§Œ ê²°ê³¼ë¡œ ì¸ì •í•©ë‹ˆë‹¤.
SIMILARITY_THRESHOLD = 0.75 # 0.0 ~ 1.0 ì‚¬ì´ ê°’

# --- AI ê¸°ë°˜ ê²€ìƒ‰ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ ---
# knowledge_baseì˜ ëª¨ë“  'question'ì— ëŒ€í•œ ì„ë² ë”© ë²¡í„°ë¥¼ ì €ì¥í•  ë³€ìˆ˜
question_embeddings = None
# ì›ë³¸ ë°ì´í„°ë¥¼ ì €ì¥í•  ë³€ìˆ˜
kb_dataframe = None

# ===================================================================
#      Part 1: ì„ë² ë”© ë° ì‹œë§¨í‹± ì„œì¹˜ ë¡œì§ (ì‹ ê·œ/ì™„ì „ ë³€ê²½)
# ===================================================================

def get_embedding(text, model="text-embedding-3-small"):
   """OpenAI ì„ë² ë”© ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜"""
   text = text.replace("\n", " ")
   return client.embeddings.create(input=[text], model=model).data[0].embedding

def cosine_similarity(A, B):
    """ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
    return np.dot(A, B) / (norm(A) * norm(B))

def initialize_knowledge_base():
    """
    (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ì‹¤í–‰)
    knowledge.csvë¥¼ ë¡œë“œí•˜ê³ , ëª¨ë“  'question'ì— ëŒ€í•œ ì„ë² ë”©ì„ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ë©”ëª¨ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    global kb_dataframe, question_embeddings
    try:
        kb_dataframe = pd.read_csv('knowledge.csv')
        print("âœ… Knowledge base loaded. Starting to generate embeddings...")

        # ë¯¸ë¦¬ ê³„ì‚°ëœ ì„ë² ë”© íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        embedding_file = 'question_embeddings.npy'
        if os.path.exists(embedding_file):
            question_embeddings = np.load(embedding_file)
            print(f"âœ… Pre-computed embeddings loaded from {embedding_file}.")
        else:
            # 'question' ì»¬ëŸ¼ì˜ ëª¨ë“  ë¬¸ì¥ì— ëŒ€í•´ ì„ë² ë”©ì„ ê³„ì‚°í•©ë‹ˆë‹¤. (ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŒ)
            # OpenAI API í˜¸ì¶œ ë¹„ìš©ì´ ë°œìƒí•©ë‹ˆë‹¤.
            kb_dataframe['embedding'] = kb_dataframe['question'].apply(lambda x: get_embedding(x))
            question_embeddings = np.array(kb_dataframe['embedding'].tolist())
            np.save(embedding_file, question_embeddings)
            print(f"âœ… Embeddings generated and saved to {embedding_file}.")

        print(f"Total entries: {len(kb_dataframe)}")

    except FileNotFoundError:
        print("ğŸš¨ FATAL ERROR: knowledge.csv file not found.")
        kb_dataframe = pd.DataFrame()

def find_relevant_info_semantic(query: str) -> list[str]:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë¯¸ì™€ ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ Nê°œì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‹œë§¨í‹± ì„œì¹˜ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    if kb_dataframe is None or kb_dataframe.empty:
        return []

    # 1. ì‚¬ìš©ì ì§ˆë¬¸ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
    query_embedding = get_embedding(query)

    # 2. ëª¨ë“  question_embeddingsì™€ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    for i, doc_embedding in enumerate(question_embeddings):
        sim = cosine_similarity(query_embedding, doc_embedding)
        if sim >= SIMILARITY_THRESHOLD:
            similarities.append((sim, i)) # (ìœ ì‚¬ë„ ì ìˆ˜, ì›ë³¸ ë°ì´í„°ì˜ ì¸ë±ìŠ¤)

    # 3. ìœ ì‚¬ë„ ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    similarities.sort(key=lambda x: x[0], reverse=True)

    # 4. ìƒìœ„ Nê°œì˜ ê²°ê³¼ì—ì„œ 'answer' í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    final_contexts = []
    for sim, index in similarities[:MAX_CONTEXT_RESULTS]:
        answer = kb_dataframe.iloc[index]['answer']
        final_contexts.append(answer)
        # ë””ë²„ê¹… ë¡œê·¸
        question = kb_dataframe.iloc[index]['question']
        print(f"  - Match (Score: {sim:.4f}): '{question[:30]}...' -> '{answer[:30]}...'")

    print(f"Found {len(final_contexts)} relevant contexts for query: '{query}'")
    return final_contexts


# ===================================================================
#      Part 2: AI ë‹µë³€ ìƒì„± ë° ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ë¡œì§ (ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼)
# ===================================================================
# generate_ai_response_advanced í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼í•˜ë¯€ë¡œ ìƒëµ...
def generate_ai_response_advanced(user_message: str, contexts: list[str]) -> str:
    context_str = "\n\n---\n\n".join(contexts)
    if not contexts:
        return "ì£„ì†¡í•˜ì§€ë§Œ ë¬¸ì˜í•˜ì‹  ë‚´ìš©ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    # ... (ì´í•˜ ì´ì „ê³¼ ë™ì¼í•œ í”„ë¡¬í”„íŠ¸ ë° API í˜¸ì¶œ ë¡œì§)
    system_instruction = "..." # ì´ì „ í”„ë¡¬í”„íŠ¸
    try:
        response = client.chat.completions.create(...) # ì´ì „ API í˜¸ì¶œ
        return response.choices[0].message.content
    except Exception as e:
        return "AI ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"


# process_and_send_callback í•¨ìˆ˜ëŠ” ê²€ìƒ‰ í•¨ìˆ˜ ì´ë¦„ë§Œ ë³€ê²½
def process_and_send_callback(user_message, callback_url):
    print("Starting background processing (Semantic Search)...")
    # <<< CHANGED >>>
    contexts = find_relevant_info_semantic(user_message)
    # ì´í•˜ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼
    ai_response_text = generate_ai_response_advanced(user_message, contexts)
    final_response_data = {"version": "2.0", "template": {"outputs": [{"simpleText": {"text": ai_response_text}}]}}
    headers = {'Content-Type': 'application/json'}
    try:
        requests.post(callback_url, data=json.dumps(final_response_data), headers=headers, timeout=10)
        print("âœ… Successfully sent semantic response via callback.")
    except requests.exceptions.RequestException as e:
        print(f"ğŸš¨ Failed to send callback to Kakao: {e}")


# ===================================================================
#      Part 3: ë©”ì¸ ì„œë²„ ë¡œì§ (ì´ˆê¸°í™” í•¨ìˆ˜ í˜¸ì¶œ ì¶”ê°€)
# ===================================================================
@app.route('/callback', methods=['POST'])
def callback():
    # (ì´ì „ ì½œë°± ë°©ì‹ ì½”ë“œì™€ ë™ì¼)
    req = request.get_json()
    user_message = req['userRequest']['utterance']
    callback_url = req['userRequest'].get('callbackUrl')
    if callback_url:
        thread = threading.Thread(target=process_and_send_callback, args=(user_message, callback_url))
        thread.start()
        return jsonify({"version": "2.0", "useCallback": True})
    else: # ë™ê¸°ì‹ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)
        contexts = find_relevant_info_semantic(user_message)
        ai_response_text = generate_ai_response_advanced(user_message, contexts)
        return jsonify({"version": "2.0", "template": {"outputs": [{"simpleText": {"text": ai_response_text}}]}})


if __name__ == '__main__':
    # (ì¤‘ìš”) ì„œë²„ê°€ ì‹œì‘ë  ë•Œ ì§€ì‹ ë² ì´ìŠ¤ ì„ë² ë”©ì„ ë¯¸ë¦¬ ìƒì„±í•©ë‹ˆë‹¤.
    initialize_knowledge_base()
    app.run(host='0.0.0.0', port=8080)